The motion for strict laws to regulate Large Language Models (LLMs) is imperative for several reasons. Firstly, LLMs possess immense capabilities that can be easily misused to generate disinformation, hate speech, or even to manipulate public opinion, creating a toxic information environment. Without regulation, LLMs could inadvertently or deliberately harm vulnerable individuals or communities. Secondly, LLMs operate on vast datasets that may contain biased or unethical content, perpetuating discrimination or inequality unless a regulatory framework ensures ethical training practices. Moreover, the potential for job displacement due to automation raises concerns about economic equity and worker rights. By implementing strict regulations, we can promote responsible development and deployment of LLMs, ensuring they align with societal values and ethical standards. Additionally, regulating transparency and accountability will help instill public trust in these technologies, allowing us to harness their benefits while minimizing risks. Strict laws are not a limitation on innovation, but rather a necessary framework for responsible growth in an increasingly digital world.